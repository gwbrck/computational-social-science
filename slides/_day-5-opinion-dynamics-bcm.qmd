# Opinion Dynamics

- thresholds were binary
- now we look at continuous opinion space

## Bounded Confidence Models

## Imports

```{python}
from mesa import Agent
from mesa import Model
from mesa.space import MultiGrid
from mesa.time import RandomActivation
from mesa.datacollection import DataCollector
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from pprint import pprint
import yaml

import icsspy
icsspy.set_style()
```

## [(BCM)]{.lightgray} The Agent Class 

```{python}
class BCMAgent(Agent):
    def __init__(self, unique_id, model, epsilon, max_agent_step_size=1):
        super().__init__(unique_id, model)
        self.opinion = self.random.uniform(-1, 1)  # Agent's opinion initialized between -1 and 1
        self.epsilon = epsilon  # Confidence bound (Îµ)
        self.max_agent_step_size = max_agent_step_size  # Step size for movement
        self.pos_history = []  # Track agent's position over time
        self.interactions = {}  # Track interactions with a count

    def step(self):
        # Move to a random neighboring cell with the given step size
        possible_moves = self.model.grid.get_neighborhood(self.pos, moore=True, include_center=False, radius=self.max_agent_step_size)
        new_position = self.random.choice(possible_moves)
        self.model.grid.move_agent(self, new_position)
        self.pos_history.append(new_position)  # Record the new position

        # Interact with neighbors within confidence bound
        neighbors = self.model.grid.get_neighbors(self.pos, moore=True, include_center=False)
        for neighbor in neighbors:
            if abs(self.opinion - neighbor.opinion) <= self.epsilon:
                # Update opinion if within confidence bound
                self.opinion = (self.opinion + neighbor.opinion) / 2

            # Record interactions
            if neighbor.unique_id in self.interactions:
                self.interactions[neighbor.unique_id] += 1
            else:
                self.interactions[neighbor.unique_id] = 1
```

## [(BCM)]{.lightgray} The Model Class 

```{python}
class BoundedConfidenceModel(Model):
    def __init__(self, grid_width, grid_height, N, epsilon, max_agent_step_size=1):
        super().__init__()
        self.num_agents = N
        self.grid = MultiGrid(grid_width, grid_height, True)
        self.schedule = RandomActivation(self)
        self.epsilon = epsilon
        self.max_agent_step_size = max_agent_step_size

        # Create agents
        for i in range(self.num_agents):
            step_size = max_agent_step_size if i % 2 == 0 else 1  # Half agents have large step size, half small
            agent = BCMAgent(i, self, epsilon, max_agent_step_size=step_size)
            self.grid.place_agent(agent, (self.random.randrange(self.grid.width),
                                          self.random.randrange(self.grid.height)))
            agent.pos_history.append(agent.pos)  # Initialize the position history with the starting position
            self.schedule.add(agent)

        self.datacollector = DataCollector(
            agent_reporters={"Opinion": "opinion"}
        )

    def step(self):
        self.datacollector.collect(self)
        self.schedule.step()

    def get_interaction_graph(self):
        G = nx.Graph()
        for agent in self.schedule.agents:
            G.add_node(agent.unique_id)
            for interacted_agent, count in agent.interactions.items():
                if G.has_edge(agent.unique_id, interacted_agent):
                    G[agent.unique_id][interacted_agent]['weight'] += count
                else:
                    G.add_edge(agent.unique_id, interacted_agent, weight=count)
        return G

```

## [(BCM)]{.lightgray} Model Parameters

```{python}
with open('_variables.yml', 'r') as file:
    params = yaml.safe_load(file)

model_params = params.get('model_0')
pprint(model_params)
```

# Run the Model & Collect Data

```{python}
model = BoundedConfidenceModel(
    grid_width=model_params['grid_width'],
    grid_height=model_params['grid_height'],
    N=model_params['N'],
    epsilon=model_params['epsilon'],
    max_agent_step_size=model_params['max_agent_step_size'],
)

for i in range(model_params['n_iterations']):
    model.step()

results = model.datacollector.get_agent_vars_dataframe().reset_index()
results.head(10)
```

## Plot Opinion Distributions

```{python}
grouped = results.groupby('Step')

plt.figure(figsize=(10, 6))  

for name, group in grouped:
    sns.kdeplot(group['Opinion'], color='C0', alpha=0.2) # clip=(-1,1) 

plt.xlabel('\nOpinion')
plt.ylabel('Density\n')
title = "Bounded Confidence Model\n" + r"$\epsilon$" + f" = {model_params['epsilon']}\n"
plt.title(title, loc='left')
plt.grid(True)
plt.savefig('media/bounded-confidence-opinion-distribution-evolution.png', dpi=300)
```

## Plot Opinions Over Time

```{python}
import matplotlib.pyplot as plt
import numpy as np

time_steps = results['Step']
opinions = results['Opinion']
title = "Bounded Confidence Model\n" + r"$\epsilon$" + f" = {model_params['epsilon']}\n"

plt.figure(figsize=(12, 6))
sc = plt.scatter(time_steps, opinions, c=opinions, cmap='coolwarm', alpha=0.5, s=10)
cbar = plt.colorbar(sc)
cbar.set_label('Opinion')
plt.xlabel('Time (Steps)')
plt.ylabel('Opinion')
plt.title(title, loc='left')
plt.xlim(time_steps.min(), time_steps.max())
plt.ylim(-1.01, 1) 
plt.savefig(f'media/bpunded_confidence_epsilon_{model_params['epsilon']}_one_run.png', dpi=300)
```

## Experimenting with $\epsilon$

Lets run the simulation with different $\epsilon$ values (e.g., -1 to 1 in steps) and collect the results in a DataFrame. The DataFrame will include an additional column to track the $\epsilon$ used in each run.

```{python}
def run_simulation_with_different_epsilons(model_params, epsilon_values):
    all_results = []

    for epsilon in epsilon_values:
        model = BoundedConfidenceModel(
            grid_width=model_params['grid_width'],
            grid_height=model_params['grid_height'],
            N=model_params['N'],
            epsilon=epsilon,
            max_agent_step_size=model_params['max_agent_step_size'],
        )
        
        for i in range(model_params['n_iterations']):
            model.step()

        epsilon_results = model.datacollector.get_agent_vars_dataframe().reset_index()
        epsilon_results['Epsilon'] = epsilon  # Add epsilon to track different values
        all_results.append(epsilon_results)

    # Combine all results into a single DataFrame
    combined_results = pd.concat(all_results, ignore_index=True)
    return combined_results
```

## Experimenting with $\epsilon$

Let's run models for the following values and plot the results.

```{python}
epsilon_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]
epsilon_results = run_simulation_with_different_epsilons(
    model_params, epsilon_values
)

epsilon_results.sample(10)
```

```{python}
epsilon_results.info()
epsilon_results.to_csv('output/bcm_epsilon_results.csv', index=False)
```

## Experimenting with $\epsilon$

Let's create some subplots to compare runs for each of our $\epsilon$ values.

```{python}
grouped = epsilon_results.groupby('Epsilon')

fig, axs = plt.subplots(
    11, 1, 
    figsize=(12, 30), 
    sharex=True, sharey=True, 
    constrained_layout=True
)

for (epsilon, group), ax in zip(grouped, axs):
    time_steps = group['Step']
    opinions = group['Opinion']
    
    sc = ax.scatter(
        time_steps, 
        opinions, 
        c=opinions, 
        cmap='coolwarm', 
        alpha=0.5, 
        s=10
    )
    
    cbar = fig.colorbar(sc, ax=ax)
    # cbar.set_label('Opinion')
    
    ax.set_title(r"$\epsilon$" + f" = {epsilon}", loc='left')
    
    ax.set_xlim(time_steps.min(), time_steps.max())
    ax.set_ylim(-1.01, 1)

# custom positions for shared x and y labels
fig.text(
    0.5, -0.01, 
    'Time (Steps)', 
    ha='center', 
    va='center', 
    fontsize=18
)

fig.text(
    -0.01, 0.5, 
    'Opinion', 
    ha='center', 
    va='center', 
    rotation='vertical', 
    fontsize=18
)

plt.savefig('output/epsilon_comparison_one_run.png', dpi=300)
```


## Batch Runs

So far we've just done single runs, but this is *not* the way to do things!

```{python}
def run_batch_simulation(model_params, n_runs):
    all_results = []

    for run_id in range(n_runs):
        model = BoundedConfidenceModel(
            grid_width=model_params['grid_width'],
            grid_height=model_params['grid_height'],
            N=model_params['N'],
            epsilon=model_params['epsilon'],
            max_agent_step_size=model_params['max_agent_step_size'],
        )
        
        for i in range(model_params['n_iterations']):
            model.step()

        run_results = model.datacollector.get_agent_vars_dataframe().reset_index()
        run_results['Run_ID'] = run_id  # Add run ID to track different runs
        run_results['Epsilon'] = model_params['epsilon']  # Add epsilon value to track each simulation
        all_results.append(run_results)

    # Combine all results into a single DataFrame
    combined_results = pd.concat(all_results, ignore_index=True)
    return combined_results

# Example usage
n_runs = 10  # Number of simulation runs
batch_results = run_batch_simulation(model_params, n_runs)
batch_results.head(10)  # Display the first 10 rows of the combined results
```

If we do 1,000 runs, the resulting csv file has 150,000,000 rows and is 4.5 GB despite only 4 numerical variables! This is a LOT of output! That's what we get from running the model 1,000 times with 100 nodes and 1,500 iterations for each model (1500*1000*100).

```{python}
batch_results.info()
```

- parameter sweeps
- analysis methods (not conventional stats -- see chapter 10)

##

Still working on the code below. I need to implement similarity calculations, etc. Mirror Smaldino here.

```python
def plot_batch_results(
    batch_results, 
    grouping_var, 
    x_var, 
    y_var, 
    hue_var, 
    n_runs, 
    title_prefix
):
    """
    Plots the results of a batch run, showing the mean and confidence intervals.
    
    Parameters:
    - batch_results: DataFrame containing the results from the batch run.
    - grouping_var: The variable to group by (e.g., 'Epsilon').
    - x_var: The variable to plot on the x-axis (e.g., 'similarity-threshold').
    - y_var: The variable to plot on the y-axis (e.g., 'average-similarity').
    - hue_var: The variable to use for color coding (e.g., 'density').
    - n_runs: Number of runs per combination to show in the title.
    - title_prefix: Prefix for the title to indicate the number of runs.
    """
    # Group the data and calculate means and standard deviations
    grouped = batch_results.groupby([grouping_var, x_var, hue_var])[y_var].agg(['mean', 'std']).reset_index()
    
    # Plot
    plt.figure(figsize=(10, 8))
    sns.lineplot(
        data=grouped, 
        x=x_var, 
        y='mean', 
        hue=hue_var, 
        marker="o", 
        ci=None,  # disable automatic confidence interval plotting
        palette="tab10"
    )
    
    # Add error bars (standard deviation)
    for _, row in grouped.iterrows():
        plt.errorbar(
            row[x_var], row['mean'], 
            yerr=row['std'], 
            fmt='o', 
            color=sns.color_palette("tab10")[int(row[hue_var] * 10) % len(sns.color_palette("tab10"))],
            alpha=0.5
        )
    
    plt.title(f"{title_prefix} {n_runs} runs per combo", loc='center')
    plt.xlabel(x_var.replace('_', ' '))
    plt.ylabel(y_var.replace('_', ' '))
    plt.legend(title=hue_var.replace('_', ' '), loc='best')
    plt.grid(True)
    plt.show()
```

```python
plot_batch_results(
    batch_results, 
    grouping_var='Epsilon', 
    x_var='similarity-threshold',
    y_var='average-similarity', 
    hue_var='density', 
    n_runs=100,
    title_prefix='100 runs per combo'
)
plt.show()
```


<!-- diffusion_of_innovations.png -->
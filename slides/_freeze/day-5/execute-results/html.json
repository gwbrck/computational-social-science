{
  "hash": "85d0be6ee6deef7d4224e0103b5ff609",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Simulation &<br>Agent-based Models\"\nsubtitle: \"[DAY FIVE]{.kn-pink} [GESIS Fall Seminar in Computational Social Science]{.kn-blue}\"\nauthor:\n  - name: John McLevey\n    affiliations:\n      - name: University of Waterloo\n  - name: Johannes B. Gruber\n    affiliations:\n      - name: VU Amsterdam\noutput-dir: \"../docs/\"\nengine: jupyter\nformat:\n  revealjs:\n    theme: [default, custom.scss]\n    width: 1600\n    height: 900\n    embed-resources: true\n    execute:\n      enabled: true\n      echo: true\n      warning: false\n      # cache: true\n      freeze: true\n    slide-number: false\n    chalkboard: false\n    preview-links: auto\n    smaller: true\n    fig-align: left\n    fig-format: svg\n    lightbox: true\n    scrollable: true\n    code-overflow: scroll\n    code-fold: false\n    code-line-numbers: true\n    code-copy: hover\n    reference-location: document\n    tbl-cap-location: margin\n    logo: media/logo_gesis.png\n    footer: \"[CC BY-SA 4.0]{.nord-footer}\"\n    email-obfuscation: javascript\nhighlight-style: \"nord\"\nbibliography: references.bib\n---\n\n\n<!-- {{< include _day-5-introduction.qmd >}} -->\n<!-- {{< include _day-5-synthetic-networks.qmd >}} -->\n\n## Imports\n\n::: {#2b11934a .cell execution_count=1}\n``` {.python .cell-code}\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport graph_tool.all as gt\nimport networkx as nx\n\nimport ndlib.models.ModelConfig as mc\nimport ndlib.models.epidemics as ep\nfrom ndlib.utils import multi_runs\n\nimport icsspy\nimport icsspy.simulations as sims\nfrom icsspy.utils import estimate_meters_from_rssi\nimport icsspy.plotting as plotting\n\nicsspy.set_style()\nrandom.seed(36)\n```\n:::\n\n\n## Data\n\n::: {#e17d9622 .cell execution_count=2}\n``` {.python .cell-code}\nbluetooth_contact = icsspy.load_data('cns_bluetooth_filtered') \nbluetooth_contact = bluetooth_contact[bluetooth_contact['rssi'] <= 0] # mistake in recorded data\nbluetooth_contact.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># timestamp</th>\n      <th>user_a</th>\n      <th>user_b</th>\n      <th>rssi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1217400</td>\n      <td>55</td>\n      <td>52</td>\n      <td>-57</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1217400</td>\n      <td>58</td>\n      <td>37</td>\n      <td>-58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1217400</td>\n      <td>111</td>\n      <td>58</td>\n      <td>-48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1217400</td>\n      <td>578</td>\n      <td>176</td>\n      <td>-36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1217700</td>\n      <td>55</td>\n      <td>52</td>\n      <td>-55</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Interactions in Time [(Timestamp)]{.kn-light}\n\nThese timestamps are relative, not absolute; they don't correspond to specific dates or times, they represent the number of seconds since the beginning of the study. They are quantized into 5-minute bins (300 seconds), where each timestamp represents the start of a 5-minute period where interactions were recorded. This means that the timestamps are best understood as **relative durations** of interactions. \n\nHowever, we can treat them as if they did correspond to specific dates and times by giving them an arbitrary start date that we will treat as the beginning of the study. We don't actually care about these dates, since they are not real, but it is convienit to work with the data this way.\n\n::: {#82164f88 .cell execution_count=3}\n``` {.python .cell-code}\narbitrary_start_date = pd.to_datetime('2019-01-01')\nbluetooth_contact['processed_timestamp'] = arbitrary_start_date + pd.to_timedelta(\n    bluetooth_contact['# timestamp'], unit='s'\n)\n\nbluetooth_contact.sample(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># timestamp</th>\n      <th>user_a</th>\n      <th>user_b</th>\n      <th>rssi</th>\n      <th>processed_timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13621</th>\n      <td>1819200</td>\n      <td>357</td>\n      <td>3</td>\n      <td>-35</td>\n      <td>2019-01-22 01:20:00</td>\n    </tr>\n    <tr>\n      <th>2634</th>\n      <td>1355700</td>\n      <td>688</td>\n      <td>178</td>\n      <td>-59</td>\n      <td>2019-01-16 16:35:00</td>\n    </tr>\n    <tr>\n      <th>16260</th>\n      <td>1958100</td>\n      <td>427</td>\n      <td>325</td>\n      <td>-59</td>\n      <td>2019-01-23 15:55:00</td>\n    </tr>\n    <tr>\n      <th>3630</th>\n      <td>1419000</td>\n      <td>651</td>\n      <td>623</td>\n      <td>-51</td>\n      <td>2019-01-17 10:10:00</td>\n    </tr>\n    <tr>\n      <th>4061</th>\n      <td>1428900</td>\n      <td>601</td>\n      <td>340</td>\n      <td>-57</td>\n      <td>2019-01-17 12:55:00</td>\n    </tr>\n    <tr>\n      <th>7879</th>\n      <td>1588200</td>\n      <td>584</td>\n      <td>379</td>\n      <td>-54</td>\n      <td>2019-01-19 09:10:00</td>\n    </tr>\n    <tr>\n      <th>16408</th>\n      <td>1961400</td>\n      <td>288</td>\n      <td>104</td>\n      <td>-59</td>\n      <td>2019-01-23 16:50:00</td>\n    </tr>\n    <tr>\n      <th>10245</th>\n      <td>1673400</td>\n      <td>427</td>\n      <td>292</td>\n      <td>-59</td>\n      <td>2019-01-20 08:50:00</td>\n    </tr>\n    <tr>\n      <th>5572</th>\n      <td>1488300</td>\n      <td>357</td>\n      <td>3</td>\n      <td>-53</td>\n      <td>2019-01-18 05:25:00</td>\n    </tr>\n    <tr>\n      <th>13782</th>\n      <td>1828200</td>\n      <td>491</td>\n      <td>208</td>\n      <td>-46</td>\n      <td>2019-01-22 03:50:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Time and Distance\n\nLet's select two users that we know have frequent interactions with one another. We'll plot the distance between these two users over a two week duration (the range of this data). To do so, we'll sort the rows (this is undirected), group by the pair of users, and count the interactions. We'll then sort the resulting dataframe to see the most frequently interacting pairs.\n\n::: {#fd1b32c9 .cell execution_count=4}\n``` {.python .cell-code}\nbluetooth_contact['user_pair'] = bluetooth_contact.apply(\n    lambda row: tuple(sorted([row['user_a'], row['user_b']])), axis=1\n)\n\npair_counts = bluetooth_contact.groupby('user_pair').size().reset_index(name='counts')\npair_counts = pair_counts.sort_values(by='counts', ascending=False)\npair_counts.head(10)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_pair</th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1645</th>\n      <td>(218, 382)</td>\n      <td>711</td>\n    </tr>\n    <tr>\n      <th>1934</th>\n      <td>(268, 521)</td>\n      <td>710</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>(136, 137)</td>\n      <td>550</td>\n    </tr>\n    <tr>\n      <th>1359</th>\n      <td>(176, 578)</td>\n      <td>449</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>(3, 357)</td>\n      <td>410</td>\n    </tr>\n    <tr>\n      <th>1608</th>\n      <td>(208, 491)</td>\n      <td>396</td>\n    </tr>\n    <tr>\n      <th>750</th>\n      <td>(90, 91)</td>\n      <td>269</td>\n    </tr>\n    <tr>\n      <th>1241</th>\n      <td>(158, 688)</td>\n      <td>265</td>\n    </tr>\n    <tr>\n      <th>1486</th>\n      <td>(190, 372)</td>\n      <td>226</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>(8, 419)</td>\n      <td>223</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe'll work with the top pair.\n\n::: {#e2c938c5 .cell execution_count=5}\n``` {.python .cell-code}\nfrequent_pair = pair_counts.iloc[0] \nuser1, user2 = frequent_pair['user_pair']\nprint(f\"Selected users with frequent interactions: {user1} and {user2}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSelected users with frequent interactions: 218 and 382\n```\n:::\n:::\n\n\n## Time and Distance\n\nLet's get their interactions from the larger dataframe. \n\n::: {#12682205 .cell execution_count=6}\n``` {.python .cell-code}\nfiltered_data = bluetooth_contact[\n    ((bluetooth_contact['user_a'] == user1) & (bluetooth_contact['user_b'] == user2)) |\n    ((bluetooth_contact['user_a'] == user2) & (bluetooth_contact['user_b'] == user1))\n]\n\n# sort by timestamp for plotting\nfiltered_data = filtered_data.sort_values(by='processed_timestamp')\nfiltered_data.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># timestamp</th>\n      <th>user_a</th>\n      <th>user_b</th>\n      <th>rssi</th>\n      <th>processed_timestamp</th>\n      <th>user_pair</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>140</th>\n      <td>1237800</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-43</td>\n      <td>2019-01-15 07:50:00</td>\n      <td>(218, 382)</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>1238100</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-41</td>\n      <td>2019-01-15 07:55:00</td>\n      <td>(218, 382)</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>1239600</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-51</td>\n      <td>2019-01-15 08:20:00</td>\n      <td>(218, 382)</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>1239900</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-52</td>\n      <td>2019-01-15 08:25:00</td>\n      <td>(218, 382)</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>1240200</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-51</td>\n      <td>2019-01-15 08:30:00</td>\n      <td>(218, 382)</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nLet's convert the RSSI values to an estimated distance (meters). We'll use the Log-Distance Path Loss Model to do this, but it will be imperfect because we can't adjust the parameters based on the environmental context (indoors, outdoors, etc.) since we don't know that information. The conversion to meters is done using the model below.\n\n::: {#47f1dd98 .cell execution_count=7}\n``` {.python .cell-code}\nfiltered_data['estimated_meters'] = estimate_meters_from_rssi(filtered_data, 'rssi')\nfiltered_data\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th># timestamp</th>\n      <th>user_a</th>\n      <th>user_b</th>\n      <th>rssi</th>\n      <th>processed_timestamp</th>\n      <th>user_pair</th>\n      <th>estimated_meters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>140</th>\n      <td>1237800</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-43</td>\n      <td>2019-01-15 07:50:00</td>\n      <td>(218, 382)</td>\n      <td>1.412538</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>1238100</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-41</td>\n      <td>2019-01-15 07:55:00</td>\n      <td>(218, 382)</td>\n      <td>1.122018</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>1239600</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-51</td>\n      <td>2019-01-15 08:20:00</td>\n      <td>(218, 382)</td>\n      <td>3.548134</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>1239900</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-52</td>\n      <td>2019-01-15 08:25:00</td>\n      <td>(218, 382)</td>\n      <td>3.981072</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>1240200</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-51</td>\n      <td>2019-01-15 08:30:00</td>\n      <td>(218, 382)</td>\n      <td>3.548134</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25008</th>\n      <td>2363100</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-54</td>\n      <td>2019-01-28 08:25:00</td>\n      <td>(218, 382)</td>\n      <td>5.011872</td>\n    </tr>\n    <tr>\n      <th>25014</th>\n      <td>2363400</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-57</td>\n      <td>2019-01-28 08:30:00</td>\n      <td>(218, 382)</td>\n      <td>7.079458</td>\n    </tr>\n    <tr>\n      <th>25018</th>\n      <td>2363700</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-57</td>\n      <td>2019-01-28 08:35:00</td>\n      <td>(218, 382)</td>\n      <td>7.079458</td>\n    </tr>\n    <tr>\n      <th>25022</th>\n      <td>2364000</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-33</td>\n      <td>2019-01-28 08:40:00</td>\n      <td>(218, 382)</td>\n      <td>0.446684</td>\n    </tr>\n    <tr>\n      <th>25026</th>\n      <td>2364300</td>\n      <td>382</td>\n      <td>218</td>\n      <td>-36</td>\n      <td>2019-01-28 08:45:00</td>\n      <td>(218, 382)</td>\n      <td>0.630957</td>\n    </tr>\n  </tbody>\n</table>\n<p>711 rows × 7 columns</p>\n</div>\n```\n:::\n:::\n\n\n## \n\nCreate a timeseries with 5-minute intervals; NaN if not present.\n\n::: {#08ac8c01 .cell execution_count=8}\n``` {.python .cell-code}\ntime_range = pd.date_range(\n    start=filtered_data['processed_timestamp'].min().floor('min'),\n    end=filtered_data['processed_timestamp'].max().ceil('min'),\n    freq='5min' # 5 min intervals\n)\n\n# convert the dataframe with intervals\ntime_series_df = pd.DataFrame(time_range, columns=['processed_timestamp'])\n\n# round the timestamps in the filtered data to the nearest 5-minute interval\nfiltered_data['rounded_timestamp'] = filtered_data['processed_timestamp'].dt.round('5min')\n\n# merge the two dataframes\nmerged_df = pd.merge(time_series_df, filtered_data[['rounded_timestamp', 'estimated_meters']],\n                     left_on='processed_timestamp', right_on='rounded_timestamp', how='left')\n\n# drop the extra column created by the merge\nmerged_df.drop(columns=['rounded_timestamp'], inplace=True)\n\n\nmerged_df\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processed_timestamp</th>\n      <th>estimated_meters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-15 07:50:00</td>\n      <td>1.412538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-15 07:55:00</td>\n      <td>1.122018</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-15 08:00:00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-15 08:05:00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-15 08:10:00</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3751</th>\n      <td>2019-01-28 08:25:00</td>\n      <td>5.011872</td>\n    </tr>\n    <tr>\n      <th>3752</th>\n      <td>2019-01-28 08:30:00</td>\n      <td>7.079458</td>\n    </tr>\n    <tr>\n      <th>3753</th>\n      <td>2019-01-28 08:35:00</td>\n      <td>7.079458</td>\n    </tr>\n    <tr>\n      <th>3754</th>\n      <td>2019-01-28 08:40:00</td>\n      <td>0.446684</td>\n    </tr>\n    <tr>\n      <th>3755</th>\n      <td>2019-01-28 08:45:00</td>\n      <td>0.630957</td>\n    </tr>\n  </tbody>\n</table>\n<p>3756 rows × 2 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.notes}\nWith this approach, even if an interaction occurs slightly before or after a 5-minute boundary, it will still be counted in the nearest 5-minute bin, preventing any gaps or inaccuracies in the distance data. The final DataFrame will accurately reflect the estimated distances between the selected users at each 5-minute interval, including interactions that don’t line up perfectly with the original bins.\n:::\n\n\n## Interactions in Space [(RSSI)]{.kn-light}\n\nNow let's plot the estimated distances between these two users over time.\n\nWe'll use the `plot_distance_per_day()` function from the course package, since the code to produce this figure is fairly complex and the specifics are beyond the scope of this course (and irrelevant to the task at hand anyway).\n\n::: {#3322c3bb .cell execution_count=9}\n``` {.python .cell-code}\nplotting.plot_distance_per_day(\n    merged_df, \n    time_col='processed_timestamp', \n    distance_col='estimated_meters', \n    num_segments=15,\n    filename='media/colocations_two_users_two_weeks.png'\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](day-5_files/figure-revealjs/cell-10-output-1.svg){}\n:::\n:::\n\n\n## Participants in Time and Space\n\n:::: {.columns}\n::: {.column width=\"75%\"}\n![What explanations are there for this temporal pattern of co-location?](media/colocations_two_users_two_weeks.png){width=100% #fig-colocations_two_users_two_weeks}\n:::\n::: {.column width=\"25%\"}\nLet's look at the physical co-locations of two participants. Remeber, we've selected two participants -- 218 and 382 -- who spend more time together than any other pair in the data.\n:::\n::::\n\n\n\n# References\n\n##\n\n",
    "supporting": [
      "day-5_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}
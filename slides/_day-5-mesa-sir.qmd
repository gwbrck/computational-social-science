# Mesa {background-image=media/robot.jpg}

Developing Your First ABM


## An MED of OOP for ABM [(sorry...)]{.nord-light}

[Object-oriented Programming (OOP), Essential Concepts]{.nord-footer}

<br>

:::: {.columns}

::: {.column width="35%"}
![[Photo by <a href="https://unsplash.com/@fairfilter?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Oliver Roos</a> on <a href="https://unsplash.com/photos/landscape-photography-of-splitted-road-surrounded-with-trees-PCNdauVPbjA?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>]{.nord-light}](media/oliver-roos-PCNdauVPbjA-unsplash.jpg){width="100%"}
:::

::: {.column width="65%"}
- **Classes** are like blueprints for creating objects (e.g., a Person class defines what properties and behaviors a person has).
- **Objects** are specific instances of a class (e.g., `maria = Person()` creates an object `maria` from the `Person` class).
- **Attributes** are variables that store data specific to an object (e.g., alice.age).
- **Methods** are functions that define behaviors of an object (e.g., `alice.move()`).
- **Inheritance** allows one class to inherit attributes and methods from another class, promoting code reuse (e.g., Professor class inherits from Person, because professors are people too).
- **Encapsulation** allows us to bundle data (attributes) and methods that operate on the data into a single unit or class, restricting direct access to some of an object’s components.
:::
::::

::: {.notes}
Introduction to OOP:

- Object-Oriented Programming (OOP) is a programming paradigm that structures software design around data, or objects, rather than functions and logic. It’s especially useful for modeling complex systems, like those you’ll encounter in agent-based modeling (ABM).

Classes and Objects:

- Think of a class as a blueprint. For example, if you’re modeling a group of people, the class might be Person. This class defines the properties (e.g., age, location) and behaviors (e.g., move, speak) that every person should have.
- An object is a specific instance of that class. If you were to create a person named Alice in your model, you would instantiate the Person class like this: alice = Person(). Now, alice is an object with her own specific age, location, and so on.

Attributes and Methods:

- Attributes are like variables that hold information about the object. For example, alice.age = 25 sets Alice’s age to 25. Each object can have different values for these attributes.
- Methods are functions that belong to the class and define what an object can do. For example, alice.move() could be a method that changes Alice’s location within the simulation.

Inheritance:

- Inheritance allows you to create a new class that is based on an existing class. If you have a Worker class that should include everything a Person has, but with some additional features, you can create Worker as a subclass of Person. This means Worker inherits all attributes and methods from Person but can also have its own unique features. This is crucial in ABM, where you might have different types of agents with shared behaviors.

Encapsulation:

- Encapsulation is the idea of keeping the internal workings of an object hidden from the outside. You can think of it as protecting the data inside an object. For example, you might not want other parts of your program to change an agent’s age directly; instead, they might call a method that safely updates the age. Encapsulation helps maintain the integrity of your model’s data and logic.

Applying OOP in Mesa:

- When you move to Mesa, you’ll use these OOP principles to define your agents as classes. Each agent will be an object of its class, with attributes that define its state (like position or health) and methods that define its behavior (like move() or interact()).
- You’ll also use inheritance to create different types of agents with shared and unique behaviors, which makes your model more scalable and easier to manage.

In short, OOP is fundamental for structuring your agent-based models in Python. By organizing your code into classes and objects, you can create agents with complex behaviors and interactions that are both manageable and scalable, which is exactly what you’ll be doing in Mesa.
:::

## Agent-based Modelling with Mesa

[Object-oriented Programming (OOP), Essential Concepts]{.nord-footer}

<br>

:::: {.columns}
::: {.column width="45%"}
- We define an [Agent Class]{.kn-pink} [(which inherits from a more general Mesa class)]{.nord-light}. Each agent created from our class is an **object** with **attributes** [(states)]{.nord-light} and **methods** [(behaviors)]{.nord-light}.
- The **environment** is typically represented as a grid or network where agents interact. The [Model class]{.kn-pink} manages the overall simulation, including initializing agents, updating them each step, and collecting data.
- The Mesa [Scheduler]{.kn-pink} determines the order in which agents act. Common options include random or sequential activation. Agents execute their actions and update their states in each step of the schedule [(i.e., a tick of time)]{.nord-light}.
- The Mesa [DataCollector]{.kn-pink} is used to gather and store data during the simulation for analysis.
:::

::: {.column width="10%"}
:::

::: {.column width="45%"}
![](media/robot.jpg){width="100%" .shadow-img}

[Agents are like little robots we manufactor according to some set of explicit instructions (the agent class).]{.nord-footer}
:::
::::

::: {.notes}
When we build agent-based models with Mesa, we apply these OOP concepts. Each agent in our models are instances of a class, meaning it has specific attributes and methods that define how it behaves in the simulation. In our SIR model, for example, each agent has a state attribute that indicates whether the agent is currently susceptible, infected, or in recovery.

The environment where our agents interact is managed by the Model class. This environment could be a grid (like a city map) or a network (like social connections). The Model class handles the setup, including creating agents and placing them in the environment, and it oversees the simulation process.

The Scheduler in Mesa is key to controlling how and when agents act. You can set agents to act in a random order, which might simulate more realistic scenarios, or in a specific sequence, depending on what makes sense for your model. This scheduling allows the simulation to evolve dynamically as agents interact with each other and the environment. Throughout the simulation, you can use the DataCollector to track various metrics—like the number of infected individuals in our SIR model. This data is crucial for analyzing the outcomes of your model.

With that, let's get into things!
:::


##

<br><br>

:::: {.columns}
::: {.column width="35%"}
![ChatGPT / DALL-E3's artistic rendering of "dependency hell."](media/chatgpt_dependency_hell.png){.shadow-img width=100%}
:::

::: {.column width="5%"}
:::

::: {.column width="60%"}
First, we set up our environment. We'll continue using the `gt` environment from yesterday. If you created it from the `setup/graphtool.yml` file, it has everything we need.

<br>

```zsh
cd computational-social-science
conda env create -f setup/graphtool.yaml
conda activate gt
```

:::
::::


##

:::: {.columns}
::: {.column width="40%"}
<br><br>

Let's develop the

### SIR model

we've been using as an example so far.
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
```{python}
import mesa
from mesa import Agent, Model
from mesa.time import RandomActivation
from mesa.space import MultiGrid
from mesa.datacollection import DataCollector
from mesa.batchrunner import batch_run
import matplotlib.pyplot as plt
from pprint import pprint
import numpy as np
import pandas as pd
import random
import yaml
import networkx as nx
import seaborn as sns
import matplotlib.pyplot as plt
import icsspy
```

<br>

Set a seed, for reproducibility, and [(optionally)]{.nord-light} use `icsspy.set_style()` to style your plots like mine.

```{python}
random.seed(42)
icsspy.set_style()
```
:::
::::


## First, define the [agent class]{.kn-pink}

<br>

```{python}
class SIRAgent(Agent):
    def __init__(
        self,
        unique_id,
        model,
        recovery_time_range=(8, 12),
        max_agent_step_size=1
    ):

        super().__init__(unique_id, model)
        self.state = "S"  # All agents start as susceptible
        self.infected_time = 0  # Counter for how long the agent has been infected
        self.recovery_time_range = recovery_time_range  # Tuple for min and max recovery times
        self.max_agent_step_size = max_agent_step_size  # Step size for movement
        self.pos_history = []  # Track agent's position over time
        self.interactions = {}  # Track interactions with a count
        self.infection_duration = 0  # Track how long the agent has been sick

    def step(self):
        if self.state == "I":
            self.infected_time += 1  # Increment the time the agent has been infected
            self.infection_duration += 1  # Increment the infection duration

            # Check if agent is within the recovery window
            if self.infected_time >= self.recovery_time_range[0]:
                if self.random.random() < 0.5 or self.infected_time >= self.recovery_time_range[1]:
                    self.state = "R"  # Recover if within the window or if max time reached

            if self.state == "I":  # Only try to infect others if still infected
                # Try to infect neighbors
                neighbors = self.model.grid.get_neighbors(self.pos, moore=True, include_center=False)
                for neighbor in neighbors:
                    if neighbor.state == "S" and self.random.random() < self.model.infection_rate:
                        neighbor.state = "I"

        # Move to a random neighboring cell with the given step size
        possible_moves = self.model.grid.get_neighborhood(
            self.pos, moore=True, include_center=False, radius=self.max_agent_step_size
        )
        new_position = self.random.choice(possible_moves)
        self.model.grid.move_agent(self, new_position)
        self.pos_history.append(new_position)  # Record the new position

        # Record interactions
        neighbors = self.model.grid.get_neighbors(
            self.pos, moore=True, include_center=False
        )
        for neighbor in neighbors:
            if neighbor.unique_id in self.interactions:
                self.interactions[neighbor.unique_id] += 1
            else:
                self.interactions[neighbor.unique_id] = 1
```

## Second, define the [model class]{.kn-pink}

<br>

```{python}
class SIRModel(Model):
    def __init__(
        self,
        grid_width,
        grid_height,
        N,
        infection_rate,
        recovery_time_range,
        max_agent_step_size=1,
        n_initial_infections=1,
        max_iterations=1000,
        change_threshold=0.001
    ):

        super().__init__()
        self.num_agents = N
        self.grid = MultiGrid(grid_width, grid_height, True)
        self.schedule = RandomActivation(self)
        self.infection_rate = infection_rate
        self.recovery_time_range = recovery_time_range
        self.max_agent_step_size = max_agent_step_size
        self.max_iterations = max_iterations
        self.current_iteration = 0
        self.change_threshold = change_threshold
        self.previous_infected_ratio = None  # Track the ratio of infected agents in the previous step

        # Create agents
        for i in range(self.num_agents):
            step_size = max_agent_step_size if i % 2 == 0 else 1  # Half agents have large step size, half small
            a = SIRAgent(i, self, recovery_time_range, max_agent_step_size=step_size)
            self.grid.place_agent(a, (self.random.randrange(self.grid.width),
                                      self.random.randrange(self.grid.height)))
            a.pos_history.append(a.pos)  # Initialize the position history with the starting position
            self.schedule.add(a)

        # Infect a specified number of random agents
        initial_infected_agents = self.random.sample(
            self.schedule.agents, n_initial_infections
        )
        for agent in initial_infected_agents:
            agent.state = "I"
            agent.infected_time = 0  # Initialize infection duration

        self.datacollector = DataCollector(
            model_reporters={
                "Susceptible": lambda m: self.count_state("S"),
                "Infected": lambda m: self.compute_infected(),
                "Recovered": lambda m: self.count_state("R")
            },
            agent_reporters={
                "State": "state",
                "Infection_Duration": "infection_duration"
            }
        )
        self.running = True  # Ensure the model runs by default

    def step(self):
        self.datacollector.collect(self)
        self.schedule.step()
        self.current_iteration += 1

        # Check for stopping condition based on maximum iterations
        if self.current_iteration >= self.max_iterations:
            self.running = False

        # Check for stopping condition based on change in infected ratio
        current_infected_ratio = self.compute_infected()
        if self.previous_infected_ratio is not None:
            change = abs(current_infected_ratio - self.previous_infected_ratio)
            if change < self.change_threshold:
                self.running = False
        self.previous_infected_ratio = current_infected_ratio

    def compute_infected(self):
        infected = sum([1 for a in self.schedule.agents if a.state == "I"])
        return infected / self.num_agents

    def count_state(self, state_name):
        count = sum([1 for a in self.schedule.agents if a.state == state_name])
        return count / self.num_agents

    def get_interaction_graph(self):
        G = nx.Graph()
        for agent in self.schedule.agents:
            G.add_node(agent.unique_id)
            for interacted_agent, count in agent.interactions.items():
                if G.has_edge(agent.unique_id, interacted_agent):
                    G[agent.unique_id][interacted_agent]['weight'] += count
                else:
                    G.add_edge(agent.unique_id, interacted_agent, weight=count)
        return G
```

## Third, load the [model parameters]{.kn-pink}

<br>

```{python}
with open('_variables.yml', 'r') as file:
    params = yaml.safe_load(file)

model_1_params = params.get('model_1')
pprint(model_1_params)
```

> output

<br>

```{python}
model_2_params = params.get('model_2')
pprint(model_2_params)
```

> output

## Forth, [run the model(s)]{.kn-pink}

<br>

We'll run two models here to reproduce @fig-sir_compare.

Here's **Model 1**

<br>

```{python}
model_1 = SIRModel(
    n_initial_infections = model_1_params['n_initial_infections'],
    grid_width = model_1_params['grid_width'],
    grid_height = model_1_params['grid_height'],
    N = model_1_params['N'],
    infection_rate = model_1_params['infection_rate'],
    recovery_time_range = model_1_params['recovery_time_range'],
    max_agent_step_size = model_1_params['max_agent_step_size'],
)

for i in range(model_1_params['n_iterations']):
    model_1.step()

m1res = model_1.datacollector.get_model_vars_dataframe()
```

## Forth, [run the model(s)]{.kn-pink}

<br>

- MODEL 1 DATAFRAME OUTPUT


## Forth, [run the model(s)]{.kn-pink}

<br>

And here's **Model 2**

<br>

```{python}
model_2 = SIRModel(
    n_initial_infections = model_2_params['n_initial_infections'],
    grid_width = model_2_params['grid_width'],
    grid_height = model_2_params['grid_height'],
    N = model_2_params['N'],
    infection_rate = model_2_params['infection_rate'],
    recovery_time_range = model_2_params['recovery_time_range'],
    max_agent_step_size = model_2_params['max_agent_step_size'],
)

for i in range(model_2_params['n_iterations']):
    model_2.step()

m2res = model_2.datacollector.get_model_vars_dataframe()
```

## Forth, [run the model(s)]{.kn-pink}

<br>

- MODEL 2 DATAFRAME OUTPUT


## Plot the results

Recall: [Design patterns]{.kn-pink}

<br>

```{python}
fig, ax = plt.subplots()
ax.plot(m1res['Infected'], label=r'High transmissability, $\beta$=0.3')
ax.plot(m2res['Infected'], label=r'Low transmissability $\beta$=0.15')
plt.xlabel("\nDiscrete Steps in Time")
plt.ylabel("Proportion Infected\n")
plt.legend(loc='upper right', fontsize=10)
plt.savefig('media/sir_compare_models_1-2.png')
```

<br>

:::: {.columns}
::: {.column width="25%"}
![](media/sir_compare){width=100%}
:::

::: {.column width="75%"}
$\longleftarrow$<br>This is @fig-sir_compare from earlier in the lecture. Proportion of infected people in a population over time from two SIR simulations with different transmissability rates.
:::
::::

<!-- (TEMPORARILY?) CUTTING THIS OUT; NO SPACE AND NOT PEDAGOGICALLY USEFUL ANYWAY -->
<!-- _day-5-CUT-illustrative-models.qmd -->

## Agent Interaction

![Who interacted with whom?](media/anthony-delanoix-hzgs56Ze49s-unsplash.jpg){width=65% .shadow-img}


## Agent Interaction

We can iterate over the agents in the model and retrieve their interaction history. [Note that we can only do this because I built that data collection into the model! We can collect just about anything we want, but only if we set things up properly.]{.nord-light} Let's construct some agent **interaction networks**!

<br>

```{python}
interaction_graphs = {}
interaction_graph_summaries = {}

models = [model_1, model_2]
for i, model in enumerate(models, start=1):
    wel = []
    for agent in model.schedule.agents:
        for k, v in agent.interactions.items():
            wel.append((int(agent.unique_id), k, v))

    G = nx.Graph()
    G.add_weighted_edges_from(wel)
    interaction_graphs[f'M{i}'] = G

    avg_degree = round(sum(dict(G.degree()).values()) / float(G.number_of_nodes()), 2)
    interaction_graph_summaries[f'M{i}'] = (G.number_of_nodes(), G.number_of_edges(), avg_degree)
```

## Agent Interaction

<br>

```{python}
interaction_graph_summaries = pd.DataFrame(interaction_graph_summaries).T
interaction_graph_summaries.columns = ['No. Nodes', 'No. Edges', 'Avg. Degree']
interaction_graph_summaries
```

```{python}
#| echo: false
from icsspy.utils import markdown_table
md = markdown_table(interaction_graph_summaries, 'tables/_sir_1_interaction_graph_summaries.md')
# print(md)
```

|   No. Nodes |   No. Edges |   Avg. Degree |
|------------:|------------:|--------------:|
|         100 |         984 |         19.68 |
|         100 |         997 |         19.94 |

<!-- won't load external table for some reason... -->

<br>

:::: {.columns}
::: {.column width="65%"}
```{python}
# Initialize an empty graph
G = interaction_graphs['M2']
weights = [d['weight'] for u, v, d in G.edges(data=True)]

plt.figure(figsize=(8, 6))
sns.ecdfplot(weights)
plt.xlabel('Interaction Weight')
plt.ylabel('ECDF')
plt.title('ECDF of Interaction Weights')
plt.grid(True)
plt.savefig('media/compare_agent_networks.png', dpi=300)
```

```{python}
#| echo: false
# testing something... ignore this... nothing to see here...
for agent in model_2.schedule.agents:
    G.add_node(agent.unique_id)  # Add agent as a node
    for interacted_agent, count in agent.interactions.items():
        if G.has_edge(agent.unique_id, interacted_agent):
            G[agent.unique_id][interacted_agent]['weight'] += count
        else:
            G.add_edge(agent.unique_id, interacted_agent, weight=count)
```
:::

::: {.column width="35%"}
![Model 2 edge weight ECDF.](media/compare_agent_networks.png){width="75%" #fig-compare_agent_networks}
:::
::::

## Analysis Chapter Summary

- TODO

## Model Analysis

<br>

:::: {.columns}
::: {.column width="60%"}
#### [Sensitivity Analysis]{.kn-pink .large-text}

helps determine which model parameters are most important and/or uncertain, and which require careful estimation and interpretation.

<br>

#### [Parameter Sweeps]{.kn-pink .large-text}

allow for a systematic exploration of how different settings influence model behavior, which helps in understanding the model's **response landscape**.

<br>

#### [Computational Experiments]{.kn-pink .large-text}

involve systematically investigating the model's behavior to answer specific questions, understand mechanisms, or test hypotheses.
:::

::: {.column width="40%"}
:::
::::

::: {.notes}
When iteratively analyzing models, we can use Sensitivity Analysis, Parameter Sweeps, and Computational Experiments to understand, test, and analyze the behavior of the model under various conditions. These methods are essential for ensuring the model’s reliability and for interpreting its results. Here’s what they mean:

1. Sensitivity Analysis

Sensitivity analysis involves systematically varying model parameters to assess how changes in these parameters affect the model’s output. It helps identify which parameters are most influential in determining model behavior and which ones have less impact.

The main goal is to understand how robust the model's results are. If small changes in a parameter lead to significant changes in outcomes, for example, that parameter is considered sensitive and could indicate areas where the model might need refinement or better data.

Local Sensitivity Analysis involves small variations in one parameter at a time to observe the local impact on the model, whereas Global Sensitivity Analysis considers a broader range of variations and the combined effects of multiple parameters.

2. Parameter Sweeps

This allows us to map out the response of the model across the entire space of possible parameter values, which helps identify trends, tipping points, or regions of parameter space where the model behaves in a particular way. Typically, this is done by running a series of simulations where one or more parameters are adjusted incrementally. The results are then analyzed to understand the relationship between parameters and outcomes.

3. Computational Experiments:

In the context of ABM, computational experiments refer to the process of systematically testing the model by varying initial conditions, parameter values, or model structures to observe the resulting behavior. Most importantly, this is done with the goal of answering scientific questions, understanding mechanisms, or testing hypotheses. Sometimes this is explicitly causal and may be similar to laboratory experiments, only in a simulated environment where variables can easily be manipulated and controlled. Other times it is more exploratory, with the goal of mapping out the model’s behavior across a wide range of conditions.
:::


# [[deeper dives with]{.small-text .light-against-image}<br>batch_run]{.pink-monospace} {background-image=media/jeremy-bishop-5MvL55-rSvI-unsplash.jpg}

<!-- Photo by <a href="https://unsplash.com/@sebaspenalambarri?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Sebastian Pena Lambarri</a> on <a href="https://unsplash.com/photos/two-people-scuba-diving-underwater-7i5HMCGupVw?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
   -->


## Using [batch_run]{.monospace}

<br>

:::: {.columns}
::: {.column width="75%"}

```{python}
params = {
    "N": 100,
    "grid_height": 40,
    "grid_width": 40,
    "infection_rate": [0.2, 0.4, 0.6, 0.8,],
    "recovery_time_range": [(7,14), (14,24)],
    "max_agent_step_size": [2, 4, 6, 8, 10, 12],
    "n_initial_infections": [1, 5, 10, 15, 20, 25]
}
```

:::

::: {.column width="25%"}
First, define a dict containing parameter valus. Use lists `[]` to configure the response space.
:::

::::

<br>

:::: {.columns}
::: {.column width="75%"}

```{python}
results = mesa.batch_run(
    model_cls=SIRModel,
    parameters=params,
    iterations=10,
    max_steps=100,
    number_processes=1,
    data_collection_period=1,  # collect data at every step
    display_progress=True,
)

results_df = pd.DataFrame(results)
results_df.info()
```

:::

::: {.column width="25%"}
Then run your model using the `batch_run()` function.
:::
::::


```{python}
#| echo: false
#
# if error on laptop, it's multi-processing in a notebook
# change number_processes to 1
#
results = mesa.batch_run(
    model_cls=SIRModel,
    parameters=params,
    iterations=10,
    max_steps=100,
    number_processes=1,
    data_collection_period=1,
    display_progress=True,
)

results_df = pd.DataFrame(results)
results_df.info()
```

##

```{python}
#| echo: false
from icsspy.utils import markdown_table
md = markdown_table(results_df.head(), 'tables/_sir_batch_results_df.md')
print(md)
```

```python
results_df.head()
```

|   RunId |   iteration |   Step |   N |   grid_height |   grid_width |   infection_rate | recovery_time_range   |   max_agent_step_size |   n_initial_infections |   Susceptible |   Infected |   Recovered |   AgentID | State   |   Infection_Duration |
|--------:|------------:|-------:|----:|--------------:|-------------:|-----------------:|:----------------------|----------------------:|-----------------------:|--------------:|-----------:|------------:|----------:|:--------|---------------------:|
|       0 |           0 |      0 | 100 |            40 |           40 |              0.2 | (7, 14)               |                     2 |                      1 |          0.99 |       0.01 |           0 |         0 | S       |                    0 |
|       0 |           0 |      0 | 100 |            40 |           40 |              0.2 | (7, 14)               |                     2 |                      1 |          0.99 |       0.01 |           0 |         1 | S       |                    0 |
|       0 |           0 |      0 | 100 |            40 |           40 |              0.2 | (7, 14)               |                     2 |                      1 |          0.99 |       0.01 |           0 |         2 | S       |                    0 |
|       0 |           0 |      0 | 100 |            40 |           40 |              0.2 | (7, 14)               |                     2 |                      1 |          0.99 |       0.01 |           0 |         3 | S       |                    0 |
|       0 |           0 |      0 | 100 |            40 |           40 |              0.2 | (7, 14)               |                     2 |                      1 |          0.99 |       0.01 |           0 |         4 | S       |                    0 |


```{python}
#| echo: false
md = markdown_table(results_df.tail(), 'tables/_sir_batch_results_df_tail.md')
print(md)
```

```python
results_df.tail()
```

|   RunId |   iteration |   Step |   N |   grid_height |   grid_width |   infection_rate | recovery_time_range   |   max_agent_step_size |   n_initial_infections |   Susceptible |   Infected |   Recovered |   AgentID | State   |   Infection_Duration |
|--------:|------------:|-------:|----:|--------------:|-------------:|-----------------:|:----------------------|----------------------:|-----------------------:|--------------:|-----------:|------------:|----------:|:--------|---------------------:|
|    2879 |           9 |     29 | 100 |            40 |           40 |              0.8 | (14, 24)              |                    12 |                     25 |          0.04 |       0.02 |        0.94 |        50 | R       |                   14 |
|    2879 |           9 |     29 | 100 |            40 |           40 |              0.8 | (14, 24)              |                    12 |                     25 |          0.04 |       0.02 |        0.94 |        91 | R       |                   20 |
|    2879 |           9 |     29 | 100 |            40 |           40 |              0.8 | (14, 24)              |                    12 |                     25 |          0.04 |       0.02 |        0.94 |        74 | R       |                   21 |
|    2879 |           9 |     29 | 100 |            40 |           40 |              0.8 | (14, 24)              |                    12 |                     25 |          0.04 |       0.02 |        0.94 |        58 | R       |                   14 |
|    2879 |           9 |     29 | 100 |            40 |           40 |              0.8 | (14, 24)              |                    12 |                     25 |          0.04 |       0.02 |        0.94 |        68 | R       |                   16 |


[Be selective about the data you collect during a batch run. I collected everything (including things that don't vary) here for pedagogical reasons only! Another run I did with this model produced a 4GB text file with only 6 variables. So, yeah.]{.nord-footer}

##

<br>

```{python}
melted_df = pd.melt(
    results_df,
    id_vars=['n_initial_infections', 'infection_rate', 'Step'],
    value_vars=['Susceptible', 'Infected', 'Recovered'],
    var_name='State',
    value_name='Proportion'
)

g = sns.FacetGrid(
    melted_df, col="n_initial_infections", hue="State", col_wrap=3, height=4, aspect=1.5
)

# map the data to the grid
g.map_dataframe(sns.lineplot, x='Step', y='Proportion')

g.add_legend()
g.set_axis_labels("Time Step", "Proportion")
g.set_titles("Initial Infections: {col_name}")

plt.savefig("media/sir_subplots.png", dpi=300)
```

##

![](media/sir_subplots.png){width="100%"}


##

- final comparison with recovery window variability?
- say more coming in other models
- make some bonus? thi sis a LOT and the core concepts are already hammered in here. Just ht eother models are more interesting.
